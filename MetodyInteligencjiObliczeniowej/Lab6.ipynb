{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zjawisko przeuczenia + regularyzacja\n",
    "## [Zadanie](http://pages.mini.pw.edu.pl/~karwowskij/mioad/lab-sieci.html#org6058800)\n",
    "\n",
    "Zaimplementować mechanizm regularyzacji wag w sieci oraz mechanizm zatrzymywania uczenia przy wzroście błędu na zbiorze walidacyjnym.\n",
    "\n",
    "Przeprowadzić eksperymenty na zbiorach i porównać skuteczność na zbiorze testowym dla różnych wariantów przeciwdziałania przeuczeniu sieci:\n",
    "- multimodal-sparse,\n",
    "- rings5-sparse,\n",
    "- rings3-balance,\n",
    "- xor3-balance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Miscellaneous classes\n",
    "\n",
    "class Sigmoid:\n",
    "    @staticmethod\n",
    "    def activate(z):\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "\n",
    "    @staticmethod\n",
    "    def derivative(z):\n",
    "        return Sigmoid.activate(z) * (1 - Sigmoid.activate(z))\n",
    "\n",
    "class Linear:\n",
    "    @staticmethod\n",
    "    def activate(z):\n",
    "        return z\n",
    "\n",
    "    @staticmethod\n",
    "    def derivative(z):\n",
    "        return np.ones(shape = z.shape)\n",
    "    \n",
    "class MSECostFunction:\n",
    "    @staticmethod\n",
    "    def cost(y_true, y_pred):\n",
    "        return np.mean((y_pred - y_true) ** 2)\n",
    "\n",
    "    @staticmethod\n",
    "    def derivative(y_true, y_pred):\n",
    "        return y_pred - y_true\n",
    "    \n",
    "class SoftMax:\n",
    "    @staticmethod\n",
    "    def activate(z):\n",
    "        e_x = np.exp(z - np.max(z))\n",
    "        return e_x / e_x.sum(axis=0, keepdims=True)\n",
    "    \n",
    "    @staticmethod\n",
    "    def derivative(z):\n",
    "        return 1\n",
    "\n",
    "class Tanh:\n",
    "    @staticmethod\n",
    "    def activate(z):\n",
    "        return np.tanh(z)\n",
    "    \n",
    "    @staticmethod\n",
    "    def derivative(z):\n",
    "        return 1 - np.power(np.tanh(z), 2)\n",
    "    \n",
    "class ReLU:\n",
    "    @staticmethod\n",
    "    def activate(z):\n",
    "        return np.maximum(0, z)\n",
    "    \n",
    "    # Not everyone implements the exact gradient for the ReLU function\n",
    "    # due to the non-differentiability of this function at 0 \n",
    "    @staticmethod\n",
    "    def derivative(z):\n",
    "        dr = np.array(z)\n",
    "        dr[dr>0] = 1\n",
    "        dr[dr<0] = 0\n",
    "        # non-differentiability at 0\n",
    "        eps = 1e-5\n",
    "        dr[dr==0] = eps\n",
    "        return dr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP:\n",
    "\n",
    "    def __init__(self, layers, initial_dist, activation_functions, softmax, cost_function=MSECostFunction):\n",
    "        \"\"\"\n",
    "        Presence of at least one hidden layer is an accompanying assumption        \n",
    "\n",
    "        Takes:        \n",
    "        layers - list of numbers of neurons in subsequent layers\n",
    "        activation_functions - list of names of functions ie ('sigmoid', 'linear')\n",
    "\n",
    "        Remarks: \n",
    "            - Length of layers list should be equal to length of activation_functions list + 1 \n",
    "            - The biases and weights for the network are initialized randomly, using continuous uniform \n",
    "              distribution with certain bounds between 0 and 1 or -1 and 1 or Gaussian distribution with mean 0, \n",
    "              and variance 1.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.layers = layers\n",
    "        self.n_layers = len(layers)\n",
    "        self.weights = []\n",
    "        self.biases = []\n",
    "        self.weights_bias_init(initial_dist)\n",
    "\n",
    "        self.activation_functions = []\n",
    "        self.activation_functions_derivatives_per_layer = []\n",
    "        for fun in activation_functions:\n",
    "            self.activation_functions.append(fun.activate)\n",
    "            self.activation_functions_derivatives_per_layer.append(fun.derivative)\n",
    "\n",
    "        self.cost_function = cost_function\n",
    "        self.softmax = softmax\n",
    "\n",
    "        if softmax:\n",
    "            self.activation_functions[-1] = activation_functions[-1].activate\n",
    "            \n",
    "    def weights_bias_init(self, initial_dist):\n",
    "        if initial_dist == \"gaussian\":\n",
    "            self.biases = [np.random.normal(size=(y, 1)) for y in self.layers[1:]]\n",
    "            self.weights = [np.random.normal(size=(y, x)) for x, y in zip(self.layers[:-1], self.layers[1:])]\n",
    "            \n",
    "        elif initial_dist == \"uniform\":\n",
    "            self.biases = [np.random.uniform(-1, 1, size=(y, 1)) for y in self.layers[1:]]\n",
    "            self.weights = [np.random.uniform(-1, 1, size=(y, x)) for x, y in zip(self.layers[:-1], self.layers[1:])]\n",
    "            \n",
    "        # Due to poor network performance with gaussian and uniform distributions in classification \n",
    "        # problems, I decided to implement xavier initialization \n",
    "        elif initial_dist == \"xavier\":\n",
    "            self.biases = [np.random.uniform(-math.sqrt(6)/ math.sqrt(self.layers[i] + self.layers[i + 1]),\n",
    "                    math.sqrt(6)/ math.sqrt(self.layers[i] + self.layers[i + 1]),size=(self.layers[i + 1], 1))\n",
    "                for i in range(self.n_layers - 1)]\n",
    "            self.weights = [np.random.uniform(-math.sqrt(6)/ math.sqrt(self.layers[i] + self.layers[i + 1]),\n",
    "                    math.sqrt(6)/ math.sqrt(self.layers[i] + self.layers[i + 1]), size=(y, x))\n",
    "                for x, y, i in zip(self.layers[:-1], self.layers[1:], range(self.n_layers))]\n",
    "        else:\n",
    "            self.biases = [np.random.uniform(0, 1, size=(y, 1)) for y in self.layers[1:]]\n",
    "            self.weights = [np.random.uniform(0, 1, size=(y, x)) for x, y in zip(self.layers[:-1], self.layers[1:])]\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Returns the output of the network if x is an input.\n",
    "        \"\"\"\n",
    "        flat_values = []\n",
    "        activation_values = [np.copy(x)]\n",
    "        for w, b, f in zip(self.weights, self.biases, self.activation_functions):\n",
    "            flat_values.append(w.dot(activation_values[-1]) + b)\n",
    "            activation_values.append(f(flat_values[-1]))\n",
    "        return (flat_values, activation_values)\n",
    "            \n",
    "            \n",
    "    def backprop(self, x_batch, y_batch):\n",
    "        \"\"\"\n",
    "        Function performing backpropagation\n",
    "        Returns nabla_b and nabla_w representing the\n",
    "        derivatives by weights and biases respectively. \n",
    "        nabla_b and nabla_w are calculated layer-by-layer.\n",
    "        \"\"\" \n",
    "        (flat_values, activation_values) = self.forward(x_batch)\n",
    "        errors = [None] * len(self.weights)\n",
    "        \n",
    "        \n",
    "        if not self.softmax:\n",
    "            errors[-1] = (-self.cost_function.derivative(y_batch, activation_values[-1])) * self.activation_functions_derivatives_per_layer[-1](flat_values[-1])\n",
    "        else:\n",
    "            errors[-1] = y_batch - activation_values[-1]\n",
    "            \n",
    "        for i in reversed(range(len(errors) - 1)):\n",
    "            errors[i] = self.weights[i + 1].T.dot(errors[i + 1]) * self.activation_functions_derivatives_per_layer[i](flat_values[i])\n",
    "        batch_size = y_batch.shape[1]\n",
    "        d_b = [e.dot(np.ones((batch_size, 1))) / float(batch_size) for e in errors]\n",
    "        d_w = [e.dot(activation_values[i].T) / float(batch_size) for i, e in enumerate(errors)]\n",
    "        return (d_w, d_b) \n",
    "    \n",
    "    def predict(self, x):\n",
    "        return self.forward(x.T)[1][-1].T\n",
    "    \n",
    "    # The following implementation is based on the derivation of the \n",
    "    # derivative formula for a new cost function with L2 regularization\n",
    "    def train_RMSProp(self, x, y, beta, batches_num = 10, epochs = 100, eta = 0.001, regression=True, regularization = False, lamb=0.03):\n",
    "       \n",
    "        # training and validation sets split\n",
    "        x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "        if regression:\n",
    "            prediction = self.predict(x_val)\n",
    "            errors = [metrics.mean_absolute_error(y_val, prediction)]\n",
    "        else:\n",
    "            prediction = self.predict(x_val)\n",
    "            prediction = np.argmax(prediction, axis=1)\n",
    "            errors = [accuracy_score(np.argmax(y_val, axis = 1), prediction)]\n",
    "            \n",
    "        for e in range(epochs):\n",
    "            grad_b = [np.zeros(b.shape) for b in self.biases]\n",
    "            grad_w = [np.zeros(w.shape) for w in self.weights]\n",
    "\n",
    "            shuffled_indexes = np.random.permutation(x_train.shape[0])\n",
    "            updated_x = x_train.copy()[shuffled_indexes]\n",
    "            updated_y = y_train.copy()[shuffled_indexes]\n",
    "\n",
    "            updated_x = np.array_split(updated_x, batches_num)\n",
    "            updated_y = np.array_split(updated_y, batches_num)\n",
    "\n",
    "            for batch in range(batches_num):\n",
    "                x_batch = updated_x[batch].T\n",
    "                y_batch = updated_y[batch].T\n",
    "                d_w, d_b = self.backprop(x_batch, y_batch)\n",
    "\n",
    "                grad_b = [(1 - beta) * np.square(db) + beta * gb for gb, db in zip(grad_b, d_b)]\n",
    "                grad_w = [(1 - beta) * np.square(dw) + beta * gw for gw, dw in zip(grad_w, d_w)]\n",
    "\n",
    "                self.biases = [b + np.divide(db, np.sqrt(gb) + 1e-8) * eta for b, gb, db in zip(self.biases, grad_b, d_b)]\n",
    "                if regularization:\n",
    "                    # modification of the method of weight change\n",
    "                    self.weights = [w*(1-eta*lamb/y_batch.shape[1]) + np.divide(dw, np.sqrt(gw) + 10e-8) * eta for w, gw, dw in zip(self.weights, grad_w, d_w)]\n",
    "                else: \n",
    "                    self.weights = [w + np.divide(dw, np.sqrt(gw) + 1e-8) * eta for w, gw, dw in zip(self.weights, grad_w, d_w)]\n",
    "            if regression:\n",
    "                prediction = self.predict(x_val)\n",
    "                errors.append(metrics.mean_absolute_error(y_val, prediction))\n",
    "            else:\n",
    "                prediction = np.argmax(self.predict(x_val), axis = 1)\n",
    "                errors.append(accuracy_score(np.argmax(y_val, axis = 1), prediction))\n",
    "            # I assume the number of epochs is at least 50\n",
    "            # Regularization protects us from too high weight values,\n",
    "            # as in each iteration they are additionally lowered by their percentage\n",
    "            if e > 50:\n",
    "                # Stop at a 10% difference between the current error value and the min/max error value \n",
    "                # All (ie min, max, current) errors are calculated on validation set for each epoch\n",
    "                if regression:\n",
    "                    if errors[e]>1.1*max(errors):\n",
    "                        return \n",
    "                else:\n",
    "                    if errors[e]<0.9*min(errors):\n",
    "                        return "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Multimodal-sparse dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "multimodal_large_train = pd.read_csv(\"../data/mio1/regression/multimodal-sparse-training.csv\")[[\"x\", \"y\"]]\n",
    "multimodal_large_test = pd.read_csv(\"../data/mio1/regression/multimodal-sparse-test.csv\")[[\"x\", \"y\"]]\n",
    "\n",
    "x_test = multimodal_large_test[\"x\"].to_numpy().reshape(-1, 1)\n",
    "y_test = multimodal_large_test[\"y\"].to_numpy().reshape(-1, 1)\n",
    "\n",
    "y_train = multimodal_large_train[\"y\"].to_numpy().reshape(-1, 1)\n",
    "x_train = multimodal_large_train[\"x\"].to_numpy().reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.1. With regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "\n",
    "for i in range(50):\n",
    "    mlp = MLP(layers=[1,40,1], initial_dist=\"default\", activation_functions=[Sigmoid, Linear], softmax=False)\n",
    "    weights = mlp.weights\n",
    "    biases = mlp.biases\n",
    "\n",
    "    mlp.train_RMSProp(x=x_train, y=y_train, eta=0.01, epochs=2000, batches_num=5, regularization=True, beta=0.9)\n",
    "    prediction = mlp.predict(x_test)\n",
    "    mae_score = metrics.mean_absolute_error(prediction, y_test)\n",
    "    scores.append(mae_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean MAE score</th>\n",
       "      <th>Max MAE score</th>\n",
       "      <th>MAE score std dev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.255764</td>\n",
       "      <td>7.868503</td>\n",
       "      <td>0.1852</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Mean MAE score  Max MAE score  MAE score std dev\n",
       "0        7.255764       7.868503             0.1852"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'Mean MAE score': np.mean(scores),\n",
    "              'Max MAE score': np.max(scores),\n",
    "             'MAE score std dev': np.std(scores)},\n",
    "            index=[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.2. Without regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "\n",
    "for i in range(50):\n",
    "    mlp = MLP(layers=[1,40,1], initial_dist=\"default\", activation_functions=[Sigmoid, Linear], softmax=False)\n",
    "    weights = mlp.weights\n",
    "    biases = mlp.biases\n",
    "\n",
    "    mlp.train_RMSProp(x=x_train, y=y_train, eta=0.01, epochs=2000, batches_num=5, regularization=False, beta=0.9)\n",
    "    prediction = mlp.predict(x_test)\n",
    "    mae_score = metrics.mean_absolute_error(prediction, y_test)\n",
    "    scores.append(mae_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean MAE score</th>\n",
       "      <th>Max MAE score</th>\n",
       "      <th>MAE score std dev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.016637</td>\n",
       "      <td>8.955756</td>\n",
       "      <td>0.253122</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Mean MAE score  Max MAE score  MAE score std dev\n",
       "0        8.016637       8.955756           0.253122"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'Mean MAE score': np.mean(scores),\n",
    "              'Max MAE score': np.max(scores),\n",
    "             'MAE score std dev': np.std(scores)},\n",
    "            index=[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Rings3 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "rings3_train = pd.read_csv(\"../data/mio1/classification/rings3-balance-training.csv\")\n",
    "rings3_test = pd.read_csv(\"../data/mio1/classification/rings3-balance-test.csv\")\n",
    "\n",
    "x_test = rings3_test[[\"x\", \"y\"]].to_numpy()\n",
    "x_train = rings3_train[[\"x\", \"y\"]].to_numpy()\n",
    "\n",
    "y_test = rings3_test[\"c\"] * 1\n",
    "n = np.max(y_test) + 1\n",
    "y_test = np.eye(n)[y_test.T]\n",
    "\n",
    "y_train = rings3_train[\"c\"] * 1\n",
    "n = np.max(y_train) + 1\n",
    "y_train = np.eye(n)[y_train.T]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.1. With regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "\n",
    "for i in range(50):\n",
    "    mlp = MLP([2,20,20,3], \"xavier\", [Sigmoid, Sigmoid, SoftMax], True)\n",
    "    weights = mlp.weights\n",
    "    biases = mlp.biases\n",
    "\n",
    "    mlp.train_RMSProp(x = x_train, y = y_train, eta = 0.001, epochs = 1000, batches_num= 10, beta=0.9, regression=False, regularization=True)\n",
    "    prediction = mlp.predict(x_test)\n",
    "    prediction = np.argmax(prediction, axis = 1)\n",
    "    acc_score = metrics.accuracy_score(np.argmax(y_test, axis = 1), prediction)\n",
    "    scores.append(acc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean Accuracy score</th>\n",
       "      <th>Max Accuracy score</th>\n",
       "      <th>Accuracy score std dev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.72509</td>\n",
       "      <td>0.7655</td>\n",
       "      <td>0.014742</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Mean Accuracy score  Max Accuracy score  Accuracy score std dev\n",
       "0              0.72509              0.7655                0.014742"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'Mean Accuracy score': np.mean(scores),\n",
    "              'Max Accuracy score': np.max(scores),\n",
    "             'Accuracy score std dev': np.std(scores)},\n",
    "            index=[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.2. Without regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "\n",
    "for i in range(50):\n",
    "    mlp = MLP([2,20,20,3], \"xavier\", [Sigmoid, Sigmoid, SoftMax], True)\n",
    "    weights = mlp.weights\n",
    "    biases = mlp.biases\n",
    "\n",
    "    mlp.train_RMSProp(x = x_train, y = y_train, eta = 0.001, epochs = 1000, batches_num= 10, beta=0.9, regression=False, regularization=False)\n",
    "    prediction = mlp.predict(x_test)\n",
    "    prediction = np.argmax(prediction, axis = 1)\n",
    "    acc_score = metrics.accuracy_score(np.argmax(y_test, axis = 1), prediction)\n",
    "    scores.append(acc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean Accuracy score</th>\n",
       "      <th>Max Accuracy score</th>\n",
       "      <th>Accuracy score std dev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.71712</td>\n",
       "      <td>0.7455</td>\n",
       "      <td>0.012418</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Mean Accuracy score  Max Accuracy score  Accuracy score std dev\n",
       "0              0.71712              0.7455                0.012418"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'Mean Accuracy score': np.mean(scores),\n",
    "              'Max Accuracy score': np.max(scores),\n",
    "              'Accuracy score std dev': np.std(scores)},\n",
    "            index=[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Rings5 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "rings5_train = pd.read_csv(\"../data/mio1/classification/rings5-sparse-training.csv\")\n",
    "rings5_test = pd.read_csv(\"../data/mio1/classification/rings5-sparse-test.csv\")\n",
    "\n",
    "x_test = rings5_test[[\"x\", \"y\"]].to_numpy()\n",
    "x_train = rings5_train[[\"x\", \"y\"]].to_numpy()\n",
    "\n",
    "y_test = rings5_test[\"c\"] * 1\n",
    "n = np.max(y_test) + 1\n",
    "y_test = np.eye(n)[y_test.T]\n",
    "\n",
    "y_train = rings5_train[\"c\"] * 1\n",
    "n = np.max(y_train) + 1\n",
    "y_train = np.eye(n)[y_train.T]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.1. With regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "\n",
    "for i in range(50):\n",
    "    mlp = MLP([2,20,20,5], \"xavier\", [Sigmoid, Sigmoid, SoftMax], True)\n",
    "    weights = mlp.weights\n",
    "    biases = mlp.biases\n",
    "\n",
    "    mlp.train_RMSProp(x = x_train, y = y_train, eta = 0.001, epochs = 1500, batches_num = 10, beta=0.9, regression=False, regularization=True)\n",
    "    prediction = mlp.predict(x_test)\n",
    "    prediction = np.argmax(prediction, axis = 1)\n",
    "    acc_score = metrics.accuracy_score(np.argmax(y_test, axis = 1), prediction)\n",
    "    scores.append(acc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean Accuracy score</th>\n",
       "      <th>Max Accuracy score</th>\n",
       "      <th>Accuracy score std dev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.75934</td>\n",
       "      <td>0.819</td>\n",
       "      <td>0.028582</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Mean Accuracy score  Max Accuracy score  Accuracy score std dev\n",
       "0              0.75934               0.819                0.028582"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'Mean Accuracy score': np.mean(scores),\n",
    "              'Max Accuracy score': np.max(scores),\n",
    "             'Accuracy score std dev': np.std(scores)},\n",
    "            index=[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.2. Without regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "\n",
    "for i in range(50):\n",
    "    mlp = MLP([2,20,20,5], \"xavier\", [Sigmoid, Sigmoid, SoftMax], True)\n",
    "    weights = mlp.weights\n",
    "    biases = mlp.biases\n",
    "\n",
    "    mlp.train_RMSProp(x = x_train, y = y_train, eta = 0.001, epochs = 1500, batches_num = 10, beta=0.9, regression=False, regularization=False)\n",
    "    prediction = mlp.predict(x_test)\n",
    "    prediction = np.argmax(prediction, axis = 1)\n",
    "    acc_score = metrics.accuracy_score(np.argmax(y_test, axis = 1), prediction)\n",
    "    scores.append(acc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean Accuracy score</th>\n",
       "      <th>Max Accuracy score</th>\n",
       "      <th>Accuracy score std dev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.75169</td>\n",
       "      <td>0.7995</td>\n",
       "      <td>0.024809</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Mean Accuracy score  Max Accuracy score  Accuracy score std dev\n",
       "0              0.75169              0.7995                0.024809"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'Mean Accuracy score': np.mean(scores),\n",
    "              'Max Accuracy score': np.max(scores),\n",
    "             'Accuracy score std dev': np.std(scores)},\n",
    "            index=[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. XOR3 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "xor_train = pd.read_csv(\"../data/mio1/classification/xor3-balance-training.csv\")\n",
    "xor_test = pd.read_csv(\"../data/mio1/classification/xor3-balance-test.csv\")\n",
    "\n",
    "x_test = xor_test[[\"x\", \"y\"]].to_numpy()\n",
    "x_train = xor_train[[\"x\", \"y\"]].to_numpy()\n",
    "\n",
    "y_test = xor_test[\"c\"] * 1\n",
    "n = np.max(y_test) + 1\n",
    "y_test = np.eye(n)[y_test.T]\n",
    "\n",
    "y_train = xor_train[\"c\"] * 1\n",
    "n = np.max(y_train) + 1\n",
    "y_train = np.eye(n)[y_train.T]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.1. With regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "\n",
    "for i in range(50):\n",
    "    mlp = MLP([2,20,2], \"xavier\", [Sigmoid, SoftMax], True)\n",
    "    weights = mlp.weights\n",
    "    biases = mlp.biases\n",
    "\n",
    "    mlp.train_RMSProp(x = x_train, y = y_train, eta = 0.001, epochs = 1500, batches_num = 10, beta=0.9, regression=False, regularization=True)\n",
    "    prediction = mlp.predict(x_test)\n",
    "    prediction = np.argmax(prediction, axis = 1)\n",
    "    acc_score = metrics.accuracy_score(np.argmax(y_test, axis = 1), prediction)\n",
    "    scores.append(acc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean Accuracy score</th>\n",
       "      <th>Max Accuracy score</th>\n",
       "      <th>Accuracy score std dev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.723525</td>\n",
       "      <td>0.77125</td>\n",
       "      <td>0.016355</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Mean Accuracy score  Max Accuracy score  Accuracy score std dev\n",
       "0             0.723525             0.77125                0.016355"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'Mean Accuracy score': np.mean(scores),\n",
    "              'Max Accuracy score': np.max(scores),\n",
    "             'Accuracy score std dev': np.std(scores)},\n",
    "            index=[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.2. Without regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "\n",
    "for i in range(50):\n",
    "    mlp = MLP([2,20,2], \"xavier\", [Sigmoid, SoftMax], True)\n",
    "    weights = mlp.weights\n",
    "    biases = mlp.biases\n",
    "\n",
    "    mlp.train_RMSProp(x = x_train, y = y_train, eta = 0.001, epochs = 1500, batches_num = 10, beta=0.9, regression=False, regularization=False)\n",
    "    prediction = mlp.predict(x_test)\n",
    "    prediction = np.argmax(prediction, axis = 1)\n",
    "    acc_score = metrics.accuracy_score(np.argmax(y_test, axis = 1), prediction)\n",
    "    scores.append(acc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean Accuracy score</th>\n",
       "      <th>Max Accuracy score</th>\n",
       "      <th>Accuracy score std dev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.725775</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.018085</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Mean Accuracy score  Max Accuracy score  Accuracy score std dev\n",
       "0             0.725775                0.76                0.018085"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'Mean Accuracy score': np.mean(scores),\n",
    "              'Max Accuracy score': np.max(scores),\n",
    "             'Accuracy score std dev': np.std(scores)},\n",
    "            index=[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
